<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Zero-PIMA | Zero-shot Pill-Prescription Matching with Graph Convolutional Network and Contrastive Learning">
  <meta name="keywords" content="Object Swapping, Personalized Editing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Zero-PIMA: Zero-shot Pill-Prescription Matching with Graph Convolutional Network and Contrastive Learning</title>
  <!-- Favicon -->
  <link rel="icon" href="static/images/pill.png" type="image/x-icon">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5MHMLLQDMS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5MHMLLQDMS');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/icon.png">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Zero-PIMA: Zero-shot Pill-Prescription Matching with Graph Convolutional Network and Contrastive Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=QSV452QAAAAJ&hl=en" target="_blank">Trung Thanh Nguyen</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=L_NKoQwAAAAJ&hl=en" target="_blank">Phi Le Nguyen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Tdfw6WMAAAAJ&hl=en" target="_blank">Yasutomo Kawanishi</a><sup>3,1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.co.jp/citations?user=j4n_V44AAAAJ&hl=en" target="_blank">Takahiro Komamizu</a><sup>4,1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8PXJm98AAAAJ&hl=en" target="_blank">Ichiro Ide</a><sup>1,4</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Graduate School of Informatics, Nagoya University, Japan</span>
            <span class="author-block"><sup>2</sup>School of Information and Communication Technology, HUST, Vietnam</span>
            <span class="author-block"><sup>3</sup>Guardian Robot Project, Information R&D and Strategy Headquarters, RIKEN, Japan</span>
            <span class="author-block"><sup>4</sup>Mathematical and Data Science Center, Nagoya University, Japan</span>
          </div>
          
          <!-- <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>Under Review</b> </b></span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper, to be public</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/thanhhff/Zero-PIMA"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://smarthealth.vinuni.edu.vn/resources/"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" style="text-align: center;">
      <img id="teaser" width="80%" src="./static/images/GA.jpg">
      <div style="text-align: center;">
        <h3 class="subtitle">
          <p>Figure 1. The proposed Zero-PIMA method leverages the pill features obtained through object localization and employs a Graph Convolutional Network (GCN) to extract pill name features from prescriptions. The matching process is achieved through contrastive learning.</p>
        </h3>
      </div>
    </div>
  </div>
</section>


<section class="section" style="background-color:#efeff081">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>

            Patients' safety is paramount in the healthcare industry, and reducing medication errors is essential for improvement. 
            A promising solution to this problem involves the development of automated systems capable of assisting patients in verifying their pill intake mistakes. 
            This paper investigates a Pill-Prescription matching task that seeks to associate pills in a multi-pill photo with their corresponding names in the prescription. 
            We specifically aim to overcome the limitations of existing pill detection methods when faced with unseen pills, a situation characteristic of zero-shot learning.
            We propose a novel method named <b>Zero-PIMA</b> (<b>Zero</b>-shot <b>Pi</b>ll-Prescription <b>Ma</b>tching), designed to match pill images with prescription names effectively, even for pills not included in the training dataset.
            Zero-PIMA is an end-to-end model that includes an object localization module to determine and extract features of pill images and a graph convolutional network to capture the spatial relationship of the pills' text in the prescription.
            After that, we leverage the contrastive learning paradigm to increase the distance between mismatched pill images and pill name pairs while minimizing the distance between matched pairs. 
            In addition, to deal with the zero-shot pill detection problem, we leverage pills' metadata retrieved from the DrugBank database to fine-tune a pre-trained text encoder, thereby incorporating visual information about pills (e.g., shape, color) into their names, making them more informative and ultimately enhancing the pill image-name matching accuracy.
            Extensive experiments are conducted on our collected real-world <span>VAIPE<sub>PP</sub></span> dataset of multi-pill photos and prescriptions. 
            Through a series of comprehensive experiments, the proposed method outperforms other methods for both seen and unseen pills in terms of mean average precision. 
            These results indicate that the proposed method could reduce medication errors and improve patients' safety.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="static/images/pill.png"> An End-to-end Pill-Prescription Matching Framework </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <div class="content has-text-justified">
              Zero-PIMA architecture consists of three modules: Pill Detector, Prescription Recognizer, and Learning Objectives.
              <ul>
                <li> Pill Detector is responsible for localizing and extracting visual information from a multi-pill photo.  </li>
                <li> Pill Prescription Recognizer utilizes a Graph Convolutional Network to highlight the text boxes likely to be pill names and a pill-enhanced text embedding to learn representations of pill names.  </li>
                <li> Textual and visual data are fed into the Pill-Prescription alignment in the Learning Objective module to produce a text-image retrieval result.</li>
              </ul>
            </div>        
            <img id="model" width="100%" src="./static/images/model.png">
              <p>Figure 2. Overview of Zero-PIMA. 
                (a) Illustration of the Zero-PIMA architecture consists of three modules: Pill Detector, Prescription Recognizer, and Learning Objectives. 
                (b) Semantic contrastive loss is applied to integrate pills’ metadata into the pill names’ embeddings.</p>
        </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="static/images/pill.png"> <span>VAIPE<sub>PP</sub></span> Dataset </h2> 
      </div>
    </div>
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <div class="content has-text-justified">
              <span>VAIPE<sub>PP</sub></span> dataset was collected in real-world scenarios, where samples were taken in unconstrained environments. 
              It consists of 2,156 multi-pill photos matching 1,527 prescriptions across 4 different templates. 
              These were collected from anonymous patients at leading hospitals in Vietnam between 2021 and 2022.
            </div>        
            <img id="model" width="60%" src="./static/images/dataset.png">
              <p>Figure 3. Representative examples from our <span>VAIPE<sub>PP</sub></span> dataset. </p>
        </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="static/images/pill.png"> Visualization </h2> 
      </div>
    </div>
      <div class="column is-six-fifths">  
        <div class="content has-text-justified">
          Visualization of some predictions for unseen pill detection. Each column presents the prescription, the ground-truth pill images, and the predictions.
      </div>   
      <div class="columns is-centered has-text-centered">
           
        <div class="column">
          <img id="model1" width="98.1%" src="./static/images/success.png">
          <p>Figure 4: Illustration of some accurate predictions</p>
        </div>
        <div class="column">
          <img id="model2" width="100%" src="./static/images/failed.png">
          <p>Figure 5: Illustration of some incorrect predictions</p>
        </div>
      </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="static/images/pill.png"> Acknowledgment </h2> 
      </div>
    </div>
      <div class="column is-six-fifths">  
        <div class="content has-text-justified">
          The computation was carried out using the General Projects on the supercomputer "Flow" with the Information Technology Center, Nagoya University. 
          This work was funded by Vingroup Joint Stock Company (Vingroup JSC), Vingroup, and supported by Vingroup Innovation Foundation (VINIF) under project code VINIF.2021.DA00128. This work was partly supported by JSPS KAKENHI JP21H0355.
      </div>   
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{nguyen2024zeropima,
      title={Zero-shot Pill-Prescription Matching with Graph Convolutional Network and Contrastive Learning}, 
      author={Trung Thanh Nguyen and Phi Le Nguyen and Kawanishi Yasutomo and Takahiro Komamizu and Ichiro Ide},
      year={2024},
      journal={IEEE Access}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>Contact: Trung Thanh NGUYEN - nguyent[at]cs.is.i.nagoya-u.ac.jp or thanh.nguyen.rc[at]a.riken.jp</p>
          <p>
            This website is adapted from <a rel="license"
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
